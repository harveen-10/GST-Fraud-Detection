# -*- coding: utf-8 -*-
"""Capstone_cleaning_B2B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KPnYKVHbW00SKdfJhUPwBOmbDNJ4Cmyr
"""

# connecting my drive to this google colab nb

from google.colab import drive
drive.mount('/content/drive')

# loading the capstone dataset folder from my drive and printing the files under it

import os

dataset_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading'
os.listdir(dataset_path)  # List files in the dataset folder

# b2b transactions dataset cleaning->
# making sure all amounts values have max 2 decimal places
# if rates are missing relace them with 0
# wherever ecommGSTIN has missing values, replace it with keyword 'NILL'

import os
import pandas as pd

# Define dataset paths
dataset_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/b2b transactions'
output_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/b2b transactions cleaned'

# Create the output folder if it doesn't exist
if not os.path.exists(output_path):
    os.makedirs(output_path)

# Process each file in the dataset folder
for file_name in os.listdir(dataset_path):
    if file_name.endswith('.csv'):
        file_path = os.path.join(dataset_path, file_name)
        df = pd.read_csv(file_path)

        # Replace null Taxable Value with 0 and ensure 2 decimal places
        df['Taxable Value'] = df['Taxable Value'].fillna(0).round(2)

        # Ensure Invoice Value has 2 decimal places
        df['Invoice Value'] = df['Invoice Value'].round(2)

        # Ensure Applicable % of Tax Rate and Rate are floating-point, replace missing with 0.0
        df['Applicable % of Tax Rate'] = pd.to_numeric(df['Applicable % of Tax Rate'], errors='coerce').fillna(0.0).astype(float)
        df['Rate'] = pd.to_numeric(df['Rate'], errors='coerce').fillna(0.0).astype(float)

        # Replace missing E-Commerce GSTIN with 'NILL'
        df['E-Commerce GSTIN'] = df['E-Commerce GSTIN'].fillna('NILL')

        # Save the modified file to the new folder with the same file name
        output_file_path = os.path.join(output_path, file_name)
        df.to_csv(output_file_path, index=False, float_format='%.2f')

import os
import pandas as pd

# Define dataset path
dataset_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/company hsn codes'

# Get the first CSV file in the folder (as a sample)
file_name = next(file for file in os.listdir(dataset_path) if file.endswith('.csv'))
file_path = os.path.join(dataset_path, file_name)

# Load the file
df = pd.read_csv(file_path)

# Check and print the datatype of the HSN column
hsn_dtype = df['HSN'].dtype
print(f"Datatype of HSN column in {file_name}: {hsn_dtype}")

# company hsn code dataset cleaning->
# only some hsn/sac code columns will have null values-> replace those with 7777

import os
import pandas as pd

# Define dataset paths
dataset_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/company hsn codes'
output_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/company hsn codes cleaned'

# Create the output folder if it doesn't exist
if not os.path.exists(output_path):
    os.makedirs(output_path)

# Process each file in the dataset folder
for file_name in os.listdir(dataset_path):
    if file_name.endswith('.csv'):
        file_path = os.path.join(dataset_path, file_name)
        df = pd.read_csv(file_path)

        # Convert HSN and SAC to string type first
        df['HSN'] = df['HSN'].astype(str)
        df['SAC'] = df['SAC'].astype(str)

        # Replace 'nan' strings and actual NaN values with '7777'
        df['HSN'] = df['HSN'].replace('nan', '7777').fillna('7777')
        df['SAC'] = df['SAC'].replace('nan', '7777').fillna('7777')


        # Save the modified file to the new folder with the same file name
        output_file_path = os.path.join(output_path, file_name)
        df.to_csv(output_file_path, index=False)

# company-transaction hsn code dataset->
# replacing the null value swith 0

# company-transaction hsn codes dataset cleaning->
# ensure specified columns have no null values, replace with 0

import os
import pandas as pd

# Define dataset paths
dataset_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/company-transaction hsn codes'
output_path = '/content/drive/My Drive/Capstone/B2B_CircularTrading/company-transaction hsn codes cleaned'

# Create the output folder if it doesn't exist
if not os.path.exists(output_path):
    os.makedirs(output_path)

# List of columns to check for null values
columns_to_clean = [
    'Taxable Value',
    'Integrated Tax Amount',
    'Central Tax Amount',
    'State/UT Tax Amount',
    'Cess Amount',
    'Rate'
]

# Process each file in the dataset folder
for file_name in os.listdir(dataset_path):
    if file_name.endswith('.csv'):
        file_path = os.path.join(dataset_path, file_name)
        df = pd.read_csv(file_path)

        # Replace null values with 0 in specified columns
        for column in columns_to_clean:
            df[column] = df[column].fillna(0)

        # Save the modified file to the new folder with the same file name
        output_file_path = os.path.join(output_path, file_name)
        df.to_csv(output_file_path, index=False)

print("\nSpecified columns cleaned (nulls replaced with 0) and saved to company-transaction hsn codes cleaned folder")

"""Basic cleaning data is done."""